install.packages("ggmap")
install.packages("readr")
install.packages("readr")
source('~/Dropbox/lecturing/GroupProject/stackoverflow_insights/non_interactive_map.R')
install.packages("plotly")
results <- read_csv("/Users/paulkelly/Dropbox/lecturing/GroupProject/stackoverflow_insights/datasets/survey_results_public.csv")
View(results)
#importing country codes Paul uploaded to github
country_codes<- read_csv("/Users/paulkelly/Dropbox/lecturing/GroupProject/stackoverflow_insights/datasets/countries.csv")
#cleaning up data
country_codes <- country_codes[c(-1)]
country_codes <- country_codes[c(3,1,2)]
colnames(country_codes) <- c("Country", "long", "lat")
#cleaning up data
country_codes <- country_codes[c(-1)]
country_codes <- country_codes[c(3,1,2)]
library(readr)
library(ggplot2)
library(stringr)
library(dplyr)
library(plyr)
# select the file from the file chooser
fileToLoad <- file.choose(new = TRUE)
# select the file from the file chooser
fileToLoad <- file.choose(new = TRUE)
# read in the CSV containing  football data and store it in a variable
surveyResultsPublic <- read.csv(fileToLoad, stringsAsFactors = FALSE)
totalDeveloperType<- surveyResultsPublic  %>% group_by(DeveloperType2) %>%  tally()
totalDeveloperType2<-na.omit(totalDeveloperType) %>% group_by(DeveloperType2) %>% tally()
totalDeveloperType2$percent<- NA
totalDeveloperType2$percent<- totalDeveloperType2$nn / sum(totalDeveloperType2$nn)
totalDeveloperType2$percent2 <- sprintf("%.0f%%", 100 * totalDeveloperType2$percent)
ggplot(totalDeveloperType2, aes(x= as.factor(DeveloperType2), y= percent2))+
geom_point(size=3, color = "Orange")+
geom_segment(aes(x=DeveloperType2,
xend=DeveloperType2,
y=0,
yend=percent2), color = "Orange")+
labs(title="Developer Types",
subtitle="All Respondents",
caption="source: stackoverflow")+
#theme(axis.text.x = element_text(angle=65, vjust=0.6))+
theme_light()+ xlab("Developer Types") + ylab("Percentage")+
coord_flip()
library(readr)
library(ggplot2)
library(stringr)
library(dplyr)
library(plyr)
library(readr)
library(ggplot2)
library(stringr)
library(dplyr)
library(plyr)
# select the file from the file chooser
fileToLoad <- file.choose(new = TRUE)
# read in the CSV containing  football data and store it in a variable
surveyResultsPublic <- read.csv(fileToLoad, stringsAsFactors = FALSE)
totalDeveloperType<- surveyResultsPublic  %>% group_by(DeveloperType2) %>%  tally()
totalDeveloperType2<-na.omit(totalDeveloperType) %>% group_by(DeveloperType2) %>% tally()
totalDeveloperType2$percent<- NA
totalDeveloperType2$percent<- totalDeveloperType2$nn / sum(totalDeveloperType2$nn)
totalDeveloperType2$percent2 <- sprintf("%.0f%%", 100 * totalDeveloperType2$percent)
ggplot(totalDeveloperType2, aes(x= as.factor(DeveloperType2), y= percent2))+
geom_point(size=3, color = "Orange")+
geom_segment(aes(x=DeveloperType2,
xend=DeveloperType2,
y=0,
yend=percent2), color = "Orange")+
labs(title="Developer Types",
subtitle="All Respondents",
caption="source: stackoverflow")+
#theme(axis.text.x = element_text(angle=65, vjust=0.6))+
theme_light()+ xlab("Developer Types") + ylab("Percentage")+
coord_flip()
library(readr)
library(ggplot2)
library(stringr)
library(dplyr)
library(plyr)
# select the file from the file chooser
fileToLoad <- file.choose(new = TRUE)
# read in the CSV containing  football data and store it in a variable
surveyResultsPublic <- read.csv(fileToLoad, stringsAsFactors = FALSE)
totalDeveloperType<- surveyResultsPublic  %>% group_by(DeveloperType2) %>%  tally()
totalDeveloperType2<-na.omit(totalDeveloperType) %>% group_by(DeveloperType2) %>% tally()
totalDeveloperType2$percent<- NA
totalDeveloperType<-surveyResultsPublic  %>% group_by(DeveloperType2) %>%  tally()
library(readr)
library(ggplot2)
library(stringr)
library(dplyr)
library(plyr)
# select the file from the file chooser
fileToLoad <- file.choose(new = TRUE)
install.packages("ggmap")
install.packages("ggmap")
library(ggmap)
library(maptools)
library(maps)
install.packages("ggmap")
library (readr)
library(tidyr)
library(plyr)
results <- read_csv("/Users/paulkelly/Dropbox/lecturing/GroupProject/stackoverflow_insights/datasets/survey_results_public.csv")
View(results)
#importing country codes Paul uploaded to github
country_codes<- read_csv("/Users/paulkelly/Dropbox/lecturing/GroupProject/stackoverflow_insights/datasets/countries.csv")
#cleaning up data
country_codes <- country_codes[c(-1)]
country_codes <- country_codes[c(3,1,2)]
colnames(country_codes) <- c("Country", "long", "lat")
#View(n)
results_pruned <- results[c(1:7)]
View(results_pruned)
head(results_pruned)
#1. survey respondents
respondents <- results_pruned[c("Respondent", "Country")]
#below I use the count function from plyr to perform count of country occurence
respondents_count <- count(respondents, "Country")
#merge respondents_count with the clean county code data using the plyr package. very clean
respondents_merged <- merge(respondents_count, country_codes, by = "Country")
respondents_merged <- na.omit(respondents_merged)
View(respondents_merged)
# Libraries
library(tidyverse)
world <- map_data("world") # we already did this, but we can do it again
gg1<-ggplot() + geom_polygon(data = world, aes(x=long, y = lat, group = group)) +
coord_fixed(1.3)
gg1 +
geom_point(data = respondents_merged, aes(x = lat, y = long), color = "blue", size = respondents_merged$freq/1000)
professional_dev <- subset(results_pruned, Professional == "Professional developer")
pro_count <- count(respondents, "Country")
#merge pro with the clean county code data using the plyr package. very clean
pro_merged <- merge(pro_count, country_codes, by = "Country")
pro_merged <- na.omit(pro_merged)
View(pro_merged)
world <- map_data("world") # we already did this, but we can do it again
gg1<-ggplot() + geom_polygon(data = world, aes(x=long, y = lat, group = group)) +
coord_fixed(1.3)
gg1 +
geom_point(data = pro_merged, aes(x = lat, y = long), color = "blue", size = pro_merged$freq/1000)
library(ggmap)
library(maptools)
library(maps)
library (readr)
library(tidyr)
library(plyr)
results <- read_csv("/Users/paulkelly/Dropbox/lecturing/GroupProject/stackoverflow_insights/datasets/survey_results_public.csv")
View(results)
#importing country codes Paul uploaded to github
country_codes<- read_csv("/Users/paulkelly/Dropbox/lecturing/GroupProject/stackoverflow_insights/datasets/countries.csv")
#cleaning up data
country_codes <- country_codes[c(-1)]
country_codes <- country_codes[c(3,1,2)]
colnames(country_codes) <- c("Country", "long", "lat")
#update
#View(n)
results_pruned <- results[c(1:7)]
View(results_pruned)
head(results_pruned)
#There are three different maps on the  stackoverflow website;
#1. survey respondents - subset on country and sum of respondants
#2. monthly stack overflow visits -
#3. professional developers - subset on developer column for professional developers and sum by country
#1. survey respondents
respondents <- results_pruned[c("Respondent", "Country")]
#below I use the count function from plyr to perform count of country occurence
respondents_count <- count(respondents, "Country")
#merge respondents_count with the clean county code data using the plyr package. very clean
respondents_merged <- merge(respondents_count, country_codes, by = "Country")
respondents_merged <- na.omit(respondents_merged)
View(respondents_merged)
#respondents_merged <- subset(respondents_merged, freq > 5)
# Libraries
library(tidyverse)
# Get the world polygon and extract U
world <- map_data("world") # we already did this, but we can do it again
gg1<-ggplot() + geom_polygon(data = world, aes(x=long, y = lat, group = group)) +
coord_fixed(1.3)
gg1 +
geom_point(data = respondents_merged, aes(x = lat, y = long), color = "blue", size = respondents_merged$freq/1000)
#2. monthly stack overflow visits -
#3. professional developers - subset on developer column for professional developers and sum by country
professional_dev <- subset(results_pruned, Professional == "Professional developer")
#below I use the count function from plyr to perform count of country occurence
pro_count <- count(respondents, "Country")
#merge pro with the clean county code data using the plyr package. very clean
pro_merged <- merge(pro_count, country_codes, by = "Country")
pro_merged <- na.omit(pro_merged)
View(pro_merged)
# Get the world polygon
world <- map_data("world") # we already did this, but we can do it again
gg1<-ggplot() + geom_polygon(data = world, aes(x=long, y = lat, group = group)) +
coord_fixed(1.3)
gg1 +
geom_point(data = pro_merged, aes(x = lat, y = long), color = "blue", size = pro_merged$freq/1000)
library(ggmap)
library(maptools)
library(maps)
library (readr)
library(tidyr)
library(plyr)
results <- read_csv("/Users/paulkelly/Dropbox/lecturing/GroupProject/stackoverflow_insights/datasets/survey_results_public.csv")
View(results)
#importing country codes Paul uploaded to github
country_codes<- read_csv("/Users/paulkelly/Dropbox/lecturing/GroupProject/stackoverflow_insights/datasets/countries.csv")
#cleaning up data
country_codes <- country_codes[c(-1)]
country_codes <- country_codes[c(3,1,2)]
colnames(country_codes) <- c("Country", "long", "lat")
#update
#View(n)
results_pruned <- results[c(1:7)]
View(results_pruned)
head(results_pruned)
#There are three different maps on the  stackoverflow website;
#1. survey respondents - subset on country and sum of respondants
#2. monthly stack overflow visits -
#3. professional developers - subset on developer column for professional developers and sum by country
#1. survey respondents
respondents <- results_pruned[c("Respondent", "Country")]
#below I use the count function from plyr to perform count of country occurence
respondents_count <- count(respondents, "Country")
#merge respondents_count with the clean county code data using the plyr package. very clean
respondents_merged <- merge(respondents_count, country_codes, by = "Country")
respondents_merged <- na.omit(respondents_merged)
View(respondents_merged)
#respondents_merged <- subset(respondents_merged, freq > 5)
# Libraries
library(tidyverse)
# Get the world polygon and extract U
world <- map_data("world") # we already did this, but we can do it again
gg1<-ggplot() + geom_polygon(data = world, aes(x=long, y = lat, group = group)) +
coord_fixed(1.3)
gg1 +
geom_point(data = respondents_merged, aes(x = lat, y = long), color = "blue", size = respondents_merged$freq/1000)
#2. monthly stack overflow visits -
#3. professional developers - subset on developer column for professional developers and sum by country
professional_dev <- subset(results_pruned, Professional == "Professional developer")
#below I use the count function from plyr to perform count of country occurence
pro_count <- count(respondents, "Country")
#merge pro with the clean county code data using the plyr package. very clean
pro_merged <- merge(pro_count, country_codes, by = "Country")
pro_merged <- na.omit(pro_merged)
View(pro_merged)
# Get the world polygon
world <- map_data("world") # we already did this, but we can do it again
gg1<-ggplot() + geom_polygon(data = world, aes(x=long, y = lat, group = group)) +
coord_fixed(1.3)
gg1 +
geom_point(data = pro_merged, aes(x = lat, y = long), color = "blue", size = pro_merged$freq/1000)
install.packages("ggplot2")
library(ggplot2)
install.packages("dplyr")
library(dplyr)
# select the file from the file chooser
fileToLoad <- file.choose(new = TRUE)
surveyResultsPublic <- read.csv(fileToLoad, stringsAsFactors = FALSE)
expDevelopers <- subset.data.frame(surveyResultsPublic, select = c("YearsProgram", "Professional"))
expDevelopers <- na.omit(expDevelopers)
expDevelopers <- filter(expDevelopers, Professional == "Professional developer")
count_expDevelopers <- as.data.frame(table(unlist(expDevelopers$YearsProgram)))
View(count_expDevelopers)
count_expDevelopers$Percentage <- count_expDevelopers$Freq / sum(count_expDevelopers$Freq) * 100
colnames(count_expDevelopers)[colnames(count_expDevelopers)=="Var1"] <- "YearsProgramming"
profDeveloperYears <- as.data.frame(matrix(NA, ncol = 2, nrow = 21))
colnames(profDeveloperYears) <- c("Years_Programming", "Percentage")
profDeveloperYears$Years_Programming <- c("Less than a year", "1 to 2 years", "2 to 3 years", "3 to 4 years",
"4 to 5 years", "5 to 6 years", "6 to 7 years", "7 to 8 years",
"8 to 9 years", "9 to 10 years", "10 to 11 years", "11 to 12 years",
"12 to 13 years", "13 to 14 years", "14 to 15 years", "15 to 16 years",
"16 to 17 years", "17 to 18 years", "18 to 19 years", "19 to 20 years", "20 or more years")
profDeveloperYears$Percentage <- c(1.10, 2.51, 3.72, 5.18,
6.53, 6.80, 5.85, 5.24,
4.14, 7.08, 5.02, 3.32,
3.18, 2.60, 4.76, 4.01,
2.52, 2.15, 1.52, 2.43, 20.33)
str(profDeveloperYears)
profDeveloperYears$Years_Programming <- factor(profDeveloperYears$Years_Programming, levels = unique(as.character(profDeveloperYears$Years_Programming)))
theme_set(theme_bw())
ggplot(profDeveloperYears, aes(x= Years_Programming, y= Percentage))+
geom_point(size=3, color = "Orange")+
geom_segment(aes(x=Years_Programming,
xend=Years_Programming,
y=0,
yend=Percentage), color = "Orange")+
labs(title="Years Programming",
subtitle="Professional Developers Only",
caption="source: stackoverflow")+
theme(axis.text.x = element_text(angle=65, vjust=0.6))+
theme_light()+
coord_flip()
library(shiny); runApp('Dropbox/lecturing/GroupProject/stackoverflow_insights/ui.R')
runApp('Dropbox/lecturing/GroupProject/stackoverflow_insights/ui.R')
runApp('Dropbox/lecturing/GroupProject/stackoverflow_insights/ui.R')
runApp('Dropbox/lecturing/GroupProject/stackoverflow_insights/ui.R')
